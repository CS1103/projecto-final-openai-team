[![Review Assignment Due Date](https://classroom.github.com/assets/deadline-readme-button-22041afd0340ce965d47ae6ef1cefeee28c7c493a6346c4f15d667ab976d596c.svg)](https://classroom.github.com/a/Lj3YlzJp)
# Proyecto Final 2025-1: AI Neural Network
## **CS2013 ProgramaciÃ³n III** Â· Informe Final

### **DescripciÃ³n**

> Ejemplo: ImplementaciÃ³n de una red neuronal multicapa en C++ para clasificaciÃ³n de dÃ­gitos manuscritos.

### Contenidos

1. [Datos generales](#datos-generales)
2. [Requisitos e instalaciÃ³n](#requisitos-e-instalaciÃ³n)
3. [InvestigaciÃ³n teÃ³rica](#1-investigaciÃ³n-teÃ³rica)
4. [DiseÃ±o e implementaciÃ³n](#2-diseÃ±o-e-implementaciÃ³n)
5. [EjecuciÃ³n](#3-ejecuciÃ³n)
6. [AnÃ¡lisis del rendimiento](#4-anÃ¡lisis-del-rendimiento)
7. [Trabajo en equipo](#5-trabajo-en-equipo)
8. [Conclusiones](#6-conclusiones)
9. [BibliografÃ­a](#7-bibliografÃ­a)
10. [Licencia](#licencia)
---

### Datos generales

* **Tema**: Redes Neuronales en AI
* **Grupo**: `group_3_custom_name`
* **Integrantes**:

  * Alumno A â€“ 209900001 (Responsable de investigaciÃ³n teÃ³rica)
  * Alumno B â€“ 209900002 (Desarrollo de la arquitectura)
  * Alumno C â€“ 209900003 (ImplementaciÃ³n del modelo)
  * Alumno D â€“ 209900004 (Pruebas y benchmarking)
  * Alumno E â€“ 209900005 (DocumentaciÃ³n y demo)

> *Nota: Reemplazar nombres y roles reales.*

---

### Requisitos e instalaciÃ³n

1. **Compilador**: GCC 11 o superior
2. **Dependencias**:

   * CMake 3.18+
   * Eigen 3.4
   * \[Otra librerÃ­a opcional]
3. **InstalaciÃ³n**:

   ```bash
   git clone https://github.com/EJEMPLO/proyecto-final.git
   cd proyecto-final
   mkdir build && cd build
   cmake ..
   make
   ```

> *Ejemplo de repositorio y comandos, ajustar segÃºn proyecto.*

---

### 1. InvestigaciÃ³n teÃ³rica

* **Objetivo**: Explorar fundamentos y arquitecturas de redes neuronales.
* **Contenido de ejemplo**:

## ðŸ§  1. Historia y evoluciÃ³n de las redes neuronales

Las redes neuronales artificiales (ANNs) nacieron como una idea inspirada en la estructura biolÃ³gica del cerebro humano.  
El primer modelo matemÃ¡tico fue propuesto por **McCulloch y Pitts** en 1943, quienes demostraron que una red simple de neuronas artificiales podÃ­a representar funciones lÃ³gicas bÃ¡sicas [3].

En 1958, el psicÃ³logo **Frank Rosenblatt** desarrollÃ³ el *perceptrÃ³n*, un algoritmo capaz de clasificar entradas linealmente separables.  
Aunque fue un avance innovador para su tiempo, presentaba limitaciones: no podÃ­a resolver problemas como la funciÃ³n XOR.  
Estas carencias llevaron a una disminuciÃ³n del interÃ©s en los aÃ±os 70.

El renacimiento llegÃ³ en los aÃ±os 80 con la introducciÃ³n del algoritmo de **retropropagaciÃ³n del error (backpropagation)**, que permitiÃ³ entrenar redes con mÃºltiples capas ocultas (*MLP*) [5].  
Este avance tÃ©cnico marcÃ³ un antes y un despuÃ©s, haciendo posible modelar relaciones no lineales de forma mÃ¡s eficiente.

A partir de la dÃ©cada de 2010, el panorama cambiÃ³ radicalmente:  
- El crecimiento del *big data*.  
- La apariciÃ³n de hardware especializado (como las GPUs).  
- Y la necesidad de resolver tareas mÃ¡s complejas...

...hicieron que las redes neuronales profundas (*deep learning*) tomaran el protagonismo en aplicaciones del mundo real [1].

> ðŸš€ Hoy en dÃ­a, las ANNs son clave en tecnologÃ­as como **ChatGPT**, sistemas de reconocimiento facial, vehÃ­culos autÃ³nomos y diagnÃ³sticos mÃ©dicos asistidos por IA.

---


## ðŸ—ï¸ 2. Principales arquitecturas: MLP, CNN y RNN

Las arquitecturas de redes neuronales definen cÃ³mo se organizan las neuronas artificiales y quÃ© tipo de datos pueden procesar eficientemente.

---

### ðŸ”¹ MLP (PerceptrÃ³n Multicapa)

El MLP es la base de muchas redes modernas. EstÃ¡ compuesto por varias capas de neuronas (una capa de entrada, una o mÃ¡s capas ocultas y una capa de salida), donde cada neurona estÃ¡ conectada a todas las de la capa siguiente [2].  
Es ideal para tareas de clasificaciÃ³n, regresiÃ³n y reconocimiento de patrones cuando los datos no tienen estructura espacial ni secuencial.

> ðŸ§  A pesar de su simplicidad, los MLP pueden aproximar funciones complejas si se entrenan correctamente y con suficientes capas.

---

### ðŸ”¹ CNN (Convolutional Neural Networks)

Las CNNs estÃ¡n especialmente diseÃ±adas para trabajar con datos estructurados en forma de matrices, como imÃ¡genes.  
Utilizan capas convolucionales que aplican filtros para detectar caracterÃ­sticas locales (bordes, texturas, colores, formas), lo que reduce el nÃºmero de parÃ¡metros necesarios y mejora el rendimiento [1].

**Aplicaciones destacadas de las CNNs:**
- ðŸ“· Reconocimiento facial en tiempo real.  
- ðŸ©º ClasificaciÃ³n de imÃ¡genes mÃ©dicas (tumores, fracturas, etc.).  
- ðŸš— Sistemas de visiÃ³n en vehÃ­culos autÃ³nomos.

---

### ðŸ”¹ RNN (Recurrent Neural Networks)

Las RNNs estÃ¡n diseÃ±adas para procesar secuencias de datos.  
A diferencia de las redes tradicionales, poseen conexiones recurrentes que les permiten â€œrecordarâ€ informaciÃ³n previa [2].

**Usos comunes de las RNNs:**
- ðŸ“ Procesamiento de lenguaje natural.  
- ðŸŒ TraducciÃ³n automÃ¡tica.  
- ðŸ’¬ AnÃ¡lisis de sentimientos.  
- ðŸ“ˆ PredicciÃ³n de series temporales (finanzas, clima, etc.).

> ðŸ§¬ Existen versiones mejoradas como **LSTM** y **GRU**, que solucionan problemas como el desvanecimiento del gradiente y permiten memorizar secuencias mÃ¡s largas.

---

## âš™ï¸ 3. Algoritmos de entrenamiento: backpropagation y optimizadores

El entrenamiento de una red neuronal consiste en ajustar sus parÃ¡metros (pesos y sesgos) para minimizar la diferencia entre la salida esperada y la obtenida.  
Para lograr esto, se utilizan dos elementos clave:

---

### ðŸ”„ Backpropagation

Es un algoritmo que aplica la **regla de la cadena** del cÃ¡lculo diferencial para distribuir el error de salida hacia las capas anteriores.  
Cada peso se actualiza en funciÃ³n del gradiente de la funciÃ³n de pÃ©rdida respecto a ese peso, permitiendo que la red aprenda patrones complejos [5].

> ðŸ’¡ Su impacto fue tal que permitiÃ³ pasar de redes simples a redes profundas con mÃºltiples capas ocultas.

---

### âš™ï¸ Optimizadores

El **optimizador** es el encargado de decidir cÃ³mo actualizar los pesos de la red durante el proceso de aprendizaje.  
Algunos de los mÃ¡s conocidos y utilizados son:

- **SGD (Stochastic Gradient Descent):**  
  Actualiza los pesos usando solo una muestra o mini-lote. Es eficiente pero puede ser sensible al *learning rate*.

- **Adam (Adaptive Moment Estimation):**  
  Combina ideas de *momentum* y adaptaciÃ³n dinÃ¡mica. Es robusto, eficiente y muy popular en la prÃ¡ctica [4].

- **RMSprop y Adagrad:**  
  Ideales para datos dispersos o ruidosos. Ajustan la tasa de aprendizaje de manera adaptativa segÃºn la frecuencia de actualizaciÃ³n de cada parÃ¡metro.

> âœ… Una buena elecciÃ³n del optimizador y de la tasa de aprendizaje (*learning rate*) puede marcar la diferencia entre una red que converge eficientemente y otra que nunca llega a aprender correctamente.


---

### 2. DiseÃ±o e implementaciÃ³n

#### 2.1 Arquitectura de la soluciÃ³n

* **Patrones de diseÃ±o**: ejemplo: Factory para capas, Strategy para optimizadores.
* **Estructura de carpetas (ejemplo)**:

  ```
  proyecto-final/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ layers/
  â”‚   â”œâ”€â”€ optimizers/
  â”‚   â””â”€â”€ main.cpp
  â”œâ”€â”€ tests/
  â””â”€â”€ docs/
  ```

#### 2.2 Manual de uso y casos de prueba

* **CÃ³mo ejecutar**: `./build/neural_net_demo input.csv output.csv`
* **Casos de prueba**:

  * Test unitario de capa densa.
  * Test de funciÃ³n de activaciÃ³n ReLU.
  * Test de convergencia en dataset de ejemplo.

> *Personalizar rutas, comandos y casos reales.*

---

### 3. EjecuciÃ³n

> **Demo de ejemplo**: Video/demo alojado en `docs/demo.mp4`.
> Pasos:
>
> 1. Preparar datos de entrenamiento (formato CSV).
> 2. Ejecutar comando de entrenamiento.
> 3. Evaluar resultados con script de validaciÃ³n.

---

### 4. AnÃ¡lisis del rendimiento

* **MÃ©tricas de ejemplo**:

  * Iteraciones: 1000 Ã©pocas.
  * Tiempo total de entrenamiento: 2m30s.
  * PrecisiÃ³n final: 92.5%.
* **Ventajas/Desventajas**:

  * * CÃ³digo ligero y dependencias mÃ­nimas.
  * â€“ Sin paralelizaciÃ³n, rendimiento limitado.
* **Mejoras futuras**:

  * Uso de BLAS para multiplicaciones (JustificaciÃ³n).
  * Paralelizar entrenamiento por lotes (JustificaciÃ³n).

---

### 5. Trabajo en equipo

| Tarea                     | Miembro  | Rol                       |
| ------------------------- | -------- | ------------------------- |
| InvestigaciÃ³n teÃ³rica     | Alumno A | Documentar bases teÃ³ricas |
| DiseÃ±o de la arquitectura | Alumno B | UML y esquemas de clases  |
| ImplementaciÃ³n del modelo | Alumno C | CÃ³digo C++ de la NN       |
| Pruebas y benchmarking    | Alumno D | GeneraciÃ³n de mÃ©tricas    |
| DocumentaciÃ³n y demo      | Alumno E | Tutorial y video demo     |

> *Actualizar con tareas y nombres reales.*

---

### 6. Conclusiones

* **Logros**: Implementar NN desde cero, validar en dataset de ejemplo.
* **EvaluaciÃ³n**: Calidad y rendimiento adecuados para propÃ³sito acadÃ©mico.
* **Aprendizajes**: ProfundizaciÃ³n en backpropagation y optimizaciÃ³n.
* **Recomendaciones**: Escalar a datasets mÃ¡s grandes y optimizar memoria.

---

### 7. BibliografÃ­a

> *Actualizar con bibliografia utilizada, al menos 4 referencias bibliograficas y usando formato IEEE de referencias bibliograficas.*

---

### Licencia

Este proyecto usa la licencia **MIT**. Ver [LICENSE](LICENSE) para detalles.

---
